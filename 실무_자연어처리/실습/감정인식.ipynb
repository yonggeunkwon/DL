{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'MELD'에 복제합니다...\n",
      "remote: Enumerating objects: 487, done.\u001b[K\n",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
      "remote: Total 487 (delta 6), reused 0 (delta 0), pack-reused 475\u001b[K\n",
      "오브젝트를 받는 중: 100% (487/487), 8.12 MiB | 22.78 MiB/s, 완료.\n",
      "델타를 알아내는 중: 100% (254/254), 완료.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/declare-lab/MELD/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kwonyonggeun/workspace/DL/실무_자연어처리/실습\n",
      "MELD  감정인식.ipynb\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./MELD/data/MELD/train_sent_emo.csv', './MELD/data/MELD/test_sent_emo.csv', './MELD/data/MELD/dev_sent_emo.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "data_path = \"./MELD/data/MELD/*.csv\"\n",
    "data_path_list = glob.glob(data_path)\n",
    "print(data_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID', 'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "for data_path in data_path_list:\n",
    "    f = open(data_path, 'r')\n",
    "    rdr = csv.reader(f)\n",
    "\n",
    "    for line in rdr:\n",
    "        print(line)\n",
    "        break\n",
    "\n",
    "    f.close()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세션으로 데이터 분할하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(session):\n",
    "    final_data = []\n",
    "    split_session = []\n",
    "    \n",
    "    for line in session:\n",
    "        split_session.append(line)\n",
    "        final_data.append(split_session[:])\n",
    "    return final_data\n",
    "\n",
    "for data_path in data_path_list:\n",
    "    f = open(data_path, 'r')\n",
    "    rdr = csv.reader(f)\n",
    "\n",
    "    \"\"\" 세션 데이터 저장 \"\"\"\n",
    "    session_dataset = []\n",
    "    session = []\n",
    "    speaker_set = []\n",
    "\n",
    "    \"\"\" 실제 데이터 저장 방식 \"\"\"\n",
    "    pre_sess = 'start'\n",
    "    for i, line in enumerate(rdr):\n",
    "        if i == 0:\n",
    "            \"\"\" 저장할 데이터들 index 확인 \"\"\"\n",
    "            header = line\n",
    "            utt_index = header.index('Utterance')\n",
    "            speaker_index = header.index('Speaker')\n",
    "            emo_index = header.index('Emotion')\n",
    "            sess_index = header.index('Dialogue_ID')\n",
    "        else:\n",
    "            utt = line[utt_index]\n",
    "            speaker = line[speaker_index]\n",
    "            emotion = line[emo_index]\n",
    "            sess = line[sess_index]\n",
    "            \n",
    "            \"\"\" 유니크한 Speaker로 바꾸기 \"\"\"\n",
    "            if speaker in speaker_set: # 이미 등장한 Speaker라면\n",
    "                uniq_speaker = speaker_set.index(speaker)            \n",
    "            else: # 등장하지 않은 Speaker \n",
    "                speaker_set.append(speaker)\n",
    "                uniq_speaker = speaker_set.index(speaker)\n",
    "\n",
    "            if pre_sess == 'start' or sess == pre_sess: # 시작이면 바로 저장 또는 \n",
    "                session.append([uniq_speaker, utt, emotion])\n",
    "            else:\n",
    "                \"\"\" 세션 데이터 저장 \"\"\"\n",
    "                session_dataset += split(session)\n",
    "                session = [[uniq_speaker, utt, emotion]]\n",
    "                speaker_set = []\n",
    "            pre_sess = sess\n",
    "\n",
    "    \"\"\" 마지막 세션 저장 \"\"\"\n",
    "    session_dataset += split(session)\n",
    "    f.close()\n",
    "\n",
    "    \"\"\" 데이터 분할하기 \"\"\"\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  'also I was the point person on my company’s transition from the KL-5 to GR-6 system.',\n",
       "  'neutral']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 발화에 대해서 sadness라고 학습시키기 위한 data\n",
    "session_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  'also I was the point person on my company’s transition from the KL-5 to GR-6 system.',\n",
       "  'neutral'],\n",
       " [1, 'You must’ve had your hands full.', 'neutral'],\n",
       " [0, 'That I did. That I did.', 'neutral'],\n",
       " [1, 'So let’s talk a little bit about your duties.', 'neutral'],\n",
       " [0, 'My duties?  All right.', 'surprise'],\n",
       " [1,\n",
       "  'Now you’ll be heading a whole division, so you’ll have a lot of duties.',\n",
       "  'neutral']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6번째 발화가 neutral이라고 학습시키기 위한 data\n",
    "session_dataset[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배치처리 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from torch.utils.data import Dataset\n",
    "def split(session):\n",
    "    final_data = []\n",
    "    split_session = []\n",
    "    for line in session:\n",
    "        split_session.append(line)\n",
    "        final_data.append(split_session[:])\n",
    "    return final_data\n",
    "\n",
    "class data_loader(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        f = open(data_path, 'r')\n",
    "        rdr = csv.reader(f)\n",
    "\n",
    "        \"\"\" 추가 \"\"\"\n",
    "        emoSet = set()\n",
    "\n",
    "        self.session_dataset = []\n",
    "        session = []\n",
    "        speaker_set = []\n",
    "\n",
    "        \"\"\" 실제 데이터 저장 방식 \"\"\"\n",
    "        pre_sess = 'start'\n",
    "        for i, line in enumerate(rdr):\n",
    "            if i == 0:\n",
    "                \"\"\" 저장할 데이터들 index 확인 \"\"\"\n",
    "                header = line\n",
    "                utt_index = header.index('Utterance')\n",
    "                speaker_index = header.index('Speaker')\n",
    "                emo_index = header.index('Emotion')\n",
    "                sess_index = header.index('Dialogue_ID')\n",
    "            else:\n",
    "                utt = line[utt_index]\n",
    "                speaker = line[speaker_index]\n",
    "                emotion = line[emo_index]\n",
    "                sess = line[sess_index]\n",
    "                \n",
    "                \"\"\" 유니크한 Speaker로 바꾸기 \"\"\"\n",
    "                if speaker in speaker_set: # 이미 등장한 Speaker라면\n",
    "                    uniq_speaker = speaker_set.index(speaker)            \n",
    "                else: # 등장하지 않은 Speaker \n",
    "                    speaker_set.append(speaker)\n",
    "                    uniq_speaker = speaker_set.index(speaker)\n",
    "\n",
    "                if pre_sess == 'start' or sess == pre_sess: # 시작이면 바로 저장 또는 \n",
    "                    session.append([uniq_speaker, utt, emotion])\n",
    "                else:\n",
    "                    \"\"\" 세션 데이터 저장 \"\"\"\n",
    "                    self.session_dataset += split(session)\n",
    "                    session = [[uniq_speaker, utt, emotion]]\n",
    "                    speaker_set = []\n",
    "                pre_sess = sess\n",
    "        \"\"\" 마지막 세션 저장 \"\"\"\n",
    "        self.session_dataset += split(session)\n",
    "        f.close()\n",
    "\n",
    "        \"\"\" 추가 \"\"\"\n",
    "        self.emoList = sorted(emoSet) # 항상 같은 레이블 순서를 유지하기 위해\n",
    "        f.close()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.session_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.session_dataset[idx]\n",
    "    \n",
    "    def collate_fn(self, sessions): # 배치를 위한 구성\n",
    "        '''\n",
    "            input:\n",
    "                data: [(session1), (session2), ...]\n",
    "            return:\n",
    "                batch_input_tokens_pad: (B, L) padded\n",
    "                batch_labels: (B)\n",
    "        '''\n",
    "        batch_input_token = []\n",
    "        for session in sessions:\n",
    "            input_token = \"\"\n",
    "            for line in session:\n",
    "                speaker, utt, emotion = line\n",
    "                input_token += utt\n",
    "            batch_input_token.append(input_token)\n",
    "\n",
    "        return batch_input_token\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 'Oh my God, he’s lost it. He’s totally lost it.', 'sadness']],\n",
       " [[0, 'Oh my God, he’s lost it. He’s totally lost it.', 'sadness'],\n",
       "  [1, 'What?', 'surprise']])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_dataset = data_loader('./MELD/data/MELD/dev_sent_emo.csv')\n",
    "dev_dataset[0], dev_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['Oh my God, he’s lost it. He’s totally lost it.', 'Oh my God, he’s lost it. He’s totally lost it.What?']\n",
      "1 ['Or! Or, we could go to the bank, close our accounts and cut them off at the source.', 'Or! Or, we could go to the bank, close our accounts and cut them off at the source.You’re a genius!']\n",
      "2 ['Or! Or, we could go to the bank, close our accounts and cut them off at the source.You’re a genius!Aww, man, now we won’t be bank buddies!', 'Or! Or, we could go to the bank, close our accounts and cut them off at the source.You’re a genius!Aww, man, now we won’t be bank buddies!Now, there’s two reasons.']\n"
     ]
    }
   ],
   "source": [
    "# 배치 결과 확인\n",
    "from torch.utils.data import DataLoader\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=2, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n",
    "\n",
    "i = 0\n",
    "for data in dev_dataloader:\n",
    "    print(i, data)\n",
    "    i += 1\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh my God, he’s lost it. He’s totally lost it.\n",
      "Oh my God, he’s lost it. He’s totally lost it.What?\n",
      "Or! Or, we could go to the bank, close our accounts and cut them off at the source.\n"
     ]
    }
   ],
   "source": [
    "# 배치 결과 확인\n",
    "from torch.utils.data import DataLoader\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=3, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n",
    "\n",
    "for data in dev_dataloader:\n",
    "    print(data[0])\n",
    "    print(data[1])\n",
    "    print(data[2])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 학습 모델들에 대한 백그라운드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af77f649cf6b4f71a0d87b396cb8c127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4383e6241f41f29a2b616fd037d47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375952b0113841bebfcb8bc484d3ae91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_additional_special_tokens',\n",
       " '_batch_encode_plus',\n",
       " '_batch_prepare_for_model',\n",
       " '_bos_token',\n",
       " '_build_conversation_input_ids',\n",
       " '_cls_token',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eos_token',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_from_pretrained',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_mask_token',\n",
       " '_pad',\n",
       " '_pad_token',\n",
       " '_pad_token_type_id',\n",
       " '_save_pretrained',\n",
       " '_sep_token',\n",
       " '_tokenize',\n",
       " '_unk_token',\n",
       " 'add_prefix_space',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'added_tokens_decoder',\n",
       " 'added_tokens_encoder',\n",
       " 'additional_special_tokens',\n",
       " 'additional_special_tokens_ids',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'as_target_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'bos_token',\n",
       " 'bos_token_id',\n",
       " 'bpe',\n",
       " 'bpe_ranks',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'byte_decoder',\n",
       " 'byte_encoder',\n",
       " 'cache',\n",
       " 'clean_up_tokenization',\n",
       " 'cls_token',\n",
       " 'cls_token_id',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'deprecation_warnings',\n",
       " 'encode',\n",
       " 'encode_plus',\n",
       " 'encoder',\n",
       " 'eos_token',\n",
       " 'eos_token_id',\n",
       " 'errors',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'mask_token',\n",
       " 'mask_token_id',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'max_model_input_sizes',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token',\n",
       " 'pad_token_id',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'pat',\n",
       " 'prepare_for_model',\n",
       " 'prepare_for_tokenization',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_init_configuration',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'sep_token',\n",
       " 'sep_token_id',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'tokenize',\n",
       " 'truncate_sequences',\n",
       " 'unique_no_split_tokens',\n",
       " 'unk_token',\n",
       " 'unk_token_id',\n",
       " 'verbose',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> </s> <pad>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 42891, 6, 42, 16, 1769, 28135, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "[0, 42891, 6, 42, 16, 1769, 28135, 2]\n",
      "{'input_ids': [[0, 42891, 6, 42, 16, 1769, 28135, 2], [0, 12196, 32, 47, 608, 116, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}\n",
      "{'input_ids': [[42891, 6, 42, 16, 1769, 28135], [12196, 32, 47, 608, 116]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 토크나이저 작동 \"\"\"\n",
    "res = tokenizer('hello, this is fastcampus')\n",
    "print(res) # 0과 2가 special token\n",
    "res = tokenizer.encode('hello, this is fastcampus')\n",
    "print(res) # 토큰의 결과만 뽑아냄\n",
    "res = tokenizer(['hello, this is fastcampus', 'what are you doing?'])\n",
    "print(res)\n",
    "res = tokenizer(['hello, this is fastcampus', 'what are you doing?'], add_special_tokens=False)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 58])\n",
      "batch_padding_token :  tensor([[    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n",
      "           827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n",
      "             5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n",
      "           328,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n",
      "           827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n",
      "             5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n",
      "           328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n",
      "            17,    27,    90,    28,   827, 30489,   328,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1],\n",
      "        [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n",
      "           827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n",
      "             5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n",
      "           328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n",
      "            17,    27,    90,    28,   827, 30489,   328,     2,   978,     6,\n",
      "            89,    17,    27,    29,    80,  2188,     4,     2]])\n",
      "batch_padding_attention_mask :  tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
      "batch_PM_input :  [[], [], [tensor([[    0,  1185,    17,    27,   241,    10, 16333,   328,     2]])]]\n",
      "batch_label :  tensor([3, 5, 4])\n"
     ]
    }
   ],
   "source": [
    "from dataset import data_loader\n",
    "from torch.utils.data import DataLoader\n",
    "dev_dataset = data_loader('./MELD/data/MELD/dev_sent_emo.csv')\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=3, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n",
    "\n",
    "for i, data in enumerate(dev_dataloader):\n",
    "    if i == 1:\n",
    "        print(data[0].shape)\n",
    "        batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n",
    "        print(\"batch_padding_token : \", batch_padding_token)\n",
    "        print(\"batch_padding_attention_mask : \", batch_padding_attention_mask)\n",
    "        print(\"batch_PM_input : \", batch_PM_input)\n",
    "        print(\"batch_label : \", batch_label)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전학습 모델 불러와서 로딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70dda11d33342c1a805c49cf22948e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031956e0bdff41eb83bfc1730fd47969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaModel\n",
    "model = RobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaModel(\n",
       "  (embeddings): RobertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (token_type_embeddings): Embedding(1, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): RobertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x RobertaLayer(\n",
       "        (attention): RobertaAttention(\n",
       "          (self): RobertaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): RobertaSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): RobertaIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): RobertaOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): RobertaPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전학습 모델 사용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 58]), torch.Size([3, 58]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch가 3이고, 총 length가 58인 상태의 입력이 들어감\n",
    "batch_padding_token.shape, batch_padding_attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n",
       "            827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n",
       "              5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n",
       "            328,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n",
       "            827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n",
       "              5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n",
       "            328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n",
       "             17,    27,    90,    28,   827, 30489,   328,     2,     1,     1,\n",
       "              1,     1,     1,     1,     1,     1,     1,     1],\n",
       "         [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n",
       "            827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n",
       "              5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n",
       "            328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n",
       "             17,    27,    90,    28,   827, 30489,   328,     2,   978,     6,\n",
       "             89,    17,    27,    29,    80,  2188,     4,     2]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 입력의 길이가 맞지 않는 경우에는 padding(pad token = 1)처리해줬는데, 이 경우에는 의미가 없으므로 attention mask가 0으로 되어 있음\n",
    "batch_padding_token, batch_padding_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 58, 768])\n",
      "torch.Size([3, 768])\n"
     ]
    }
   ],
   "source": [
    "batch_com_out = model(input_ids = batch_padding_token, attention_mask = batch_padding_attention_mask)['last_hidden_state']\n",
    "print(batch_com_out.shape)\n",
    "batch_com_final = batch_com_out[:,0,:] # CLS 토큰의 output을 가져오기 위해\n",
    "print(batch_com_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model(input_ids = batch_padding_token, attention_mask = batch_padding_attention_mask)\n",
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
