{"cells":[{"cell_type":"markdown","id":"9959a4b1-e180-4436-a79f-370e294d2604","metadata":{"id":"9959a4b1-e180-4436-a79f-370e294d2604"},"source":["# **라이브러리 설치**"]},{"cell_type":"code","execution_count":1,"id":"a8c8e066-a9d8-481b-a005-7994a7a414f6","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8c8e066-a9d8-481b-a005-7994a7a414f6","executionInfo":{"status":"ok","timestamp":1663995407044,"user_tz":-540,"elapsed":18112,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"7fa5fa75-a6a0-497c-b53a-bb0ccef7f50b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.4.0\n","  Downloading transformers-4.4.0-py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 30.8 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 59.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0) (4.12.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0) (21.3)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 55.6 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.4.0) (2022.6.2)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.4.0) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.4.0) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.4.0) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.4.0) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.0) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.4.0) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=bc6819927bec1634c1c01b68e87ab0fa6193f77c96309698ced7757589ca3eeb\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.4.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sklearn\n","  Downloading sklearn-0.0.tar.gz (1.1 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n","Building wheels for collected packages: sklearn\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=1aba95ecab32698dd2f994e0aed3f42428553b592875fa21061d515719743157\n","  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n","Successfully built sklearn\n","Installing collected packages: sklearn\n","Successfully installed sklearn-0.0\n"]}],"source":["# !pip install torch\n","!pip install transformers==4.4.0\n","!pip install sklearn"]},{"cell_type":"code","execution_count":2,"id":"26ffc9d9-c53c-488a-a936-1d93efe90464","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"26ffc9d9-c53c-488a-a936-1d93efe90464","executionInfo":{"status":"ok","timestamp":1663995410370,"user_tz":-540,"elapsed":3330,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"c5c564aa-f9ee-40b6-dc82-bec16556812d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.12.1+cu113'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}],"source":["import torch\n","torch.__version__"]},{"cell_type":"code","source":["import transformers\n","transformers.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"AdXiO7fzNtsc","executionInfo":{"status":"ok","timestamp":1663995410371,"user_tz":-540,"elapsed":13,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"a99bddc5-1de5-47e0-aac3-6ac22afa477a"},"id":"AdXiO7fzNtsc","execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'4.4.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZSzNcuLdxfyn","executionInfo":{"status":"ok","timestamp":1663995410371,"user_tz":-540,"elapsed":11,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"321b1c40-10c4-4bea-d6bd-0390ab20b39c"},"id":"ZSzNcuLdxfyn","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Sep 24 04:56:50 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   53C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","id":"0fd6fb44-a396-4caa-a617-dea844dab57d","metadata":{"id":"0fd6fb44-a396-4caa-a617-dea844dab57d"},"source":["# **데이터 다운로드**"]},{"cell_type":"code","execution_count":5,"id":"7f68349f-777a-49dd-9a3b-6f8bf4bfd57d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7f68349f-777a-49dd-9a3b-6f8bf4bfd57d","executionInfo":{"status":"ok","timestamp":1663995431213,"user_tz":-540,"elapsed":3528,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"5835f218-ff1d-485e-cb17-c13766948b1d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'MELD'...\n","remote: Enumerating objects: 475, done.\u001b[K\n","remote: Total 475 (delta 0), reused 0 (delta 0), pack-reused 475\u001b[K\n","Receiving objects: 100% (475/475), 8.11 MiB | 6.03 MiB/s, done.\n","Resolving deltas: 100% (248/248), done.\n"]}],"source":["!git clone https://github.com/declare-lab/MELD.git"]},{"cell_type":"code","execution_count":6,"id":"3c2a745b-ff12-4a34-b312-f508f88840fa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3c2a745b-ff12-4a34-b312-f508f88840fa","executionInfo":{"status":"ok","timestamp":1663995431214,"user_tz":-540,"elapsed":15,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"874a0340-ead3-4bb6-8a63-91d28d48780c"},"outputs":[{"output_type":"stream","name":"stdout","text":["['./MELD/data/MELD/train_sent_emo.csv', './MELD/data/MELD/dev_sent_emo.csv', './MELD/data/MELD/test_sent_emo.csv']\n"]}],"source":["import glob\n","data_path = \"./MELD/data/MELD/*.csv\"\n","data_path_list = glob.glob(data_path)\n","print(data_path_list)"]},{"cell_type":"markdown","id":"0c28b8b6-bc73-4122-b842-8f3a80c02d5b","metadata":{"id":"0c28b8b6-bc73-4122-b842-8f3a80c02d5b"},"source":["## 데이터 확인"]},{"cell_type":"code","execution_count":7,"id":"e0bf3c7f-7878-431d-993a-6568e4ca122d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e0bf3c7f-7878-431d-993a-6568e4ca122d","executionInfo":{"status":"ok","timestamp":1663995431214,"user_tz":-540,"elapsed":12,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"980e5fcf-2bf4-409a-8076-15feeb2ffb61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sr No.,Utterance,Speaker,Emotion,Sentiment,Dialogue_ID,Utterance_ID,Season,Episode,StartTime,EndTime\r\n","1,\"Oh my God, he’s lost it. He’s totally lost it.\",Phoebe,sadness,negative,0,0,4,7,\"00:20:57,256\",\"00:21:00,049\"\r\n","2,What?,Monica,surprise,negative,0,1,4,7,\"00:21:01,927\",\"00:21:03,261\"\r\n","3,\"Or! Or, we could go to the bank, close our accounts and cut them off at the source.\",Ross,neutral,neutral,1,0,4,4,\"00:12:24,660\",\"00:12:30,915\"\r\n","4,You’re a genius!,Chandler,joy,positive,1,1,4,4,\"00:12:32,334\",\"00:12:33,960\"\r\n"]}],"source":["!head -5 './MELD/data/MELD/dev_sent_emo.csv'"]},{"cell_type":"code","execution_count":8,"id":"5b6c3a54-044e-4554-a5c9-bb5ee8e4a93c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5b6c3a54-044e-4554-a5c9-bb5ee8e4a93c","executionInfo":{"status":"ok","timestamp":1663995431215,"user_tz":-540,"elapsed":9,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"0bf50167-ce22-423d-f04f-c81cb38d7bb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["['Sr No.', 'Utterance', 'Speaker', 'Emotion', 'Sentiment', 'Dialogue_ID', 'Utterance_ID', 'Season', 'Episode', 'StartTime', 'EndTime']\n"]}],"source":["# 데이터 출력\n","import csv\n","for data_path in data_path_list:\n","    f = open(data_path, 'r')\n","    rdr = csv.reader(f)\n","    \n","    for line in rdr:\n","        print(line)\n","        break\n","        \n","    f.close()\n","    break"]},{"cell_type":"markdown","id":"1d71003f-32a1-4c99-8dea-2fe86d6eeec6","metadata":{"id":"1d71003f-32a1-4c99-8dea-2fe86d6eeec6"},"source":["## 세션으로 데이터 분할하기"]},{"cell_type":"code","source":["[발화1, 발화2, 발화3] --> 감정예측한다는 것은 발화3에 해당하는 감정을\n","여기서 발화1, 발화2에 해당하는 감정이 있고, 이를 학습데이터로 사용해야된다.\n","--> [발화1], [발화1, 발화2]\n","\n","//\n","모델이 roberta: bidirectional\n",": attention이 양방향\n","\n","[발화1, 발화2, 발화3]: 여기서 발화2에 해당하는 감정을 학습한다.\n",": 동시에 발화1에 해당하는 감정을 학습한다."],"metadata":{"id":"vntvtp71P2F9"},"id":"vntvtp71P2F9","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":9,"id":"5f398b2c-7d26-4466-b298-92a545cc7e16","metadata":{"id":"5f398b2c-7d26-4466-b298-92a545cc7e16","executionInfo":{"status":"ok","timestamp":1663995435213,"user_tz":-540,"elapsed":554,"user":{"displayName":"이주성","userId":"05491312179909265297"}}},"outputs":[],"source":["# 데이터 저장\n","def split(session):\n","    final_data = []\n","    split_session = []\n","    for line in session:\n","        split_session.append(line)\n","        final_data.append(split_session[:])    \n","    return final_data\n","    \n","for data_path in data_path_list:\n","    f = open(data_path, 'r')\n","    rdr = csv.reader(f)\n","    \n","    \"\"\" 세션 데이터 저장할 것\"\"\"\n","    session_dataset = []\n","    session = []\n","    speaker_set = []\n","    \n","    \"\"\" 실제 데이터 저장 방식 \"\"\"\n","    pre_sess = 'start'\n","    for i, line in enumerate(rdr):\n","        if i == 0:\n","            \"\"\" 저장할 데이터들 index 확인 \"\"\"\n","            header  = line\n","            utt_idx = header.index('Utterance')\n","            speaker_idx = header.index('Speaker')\n","            emo_idx = header.index('Emotion')\n","            sess_idx = header.index('Dialogue_ID')\n","        else:\n","            utt = line[utt_idx]\n","            speaker = line[speaker_idx]\n","            \"\"\" 유니크한 스피커로 바꾸기 \"\"\"\n","            if speaker in speaker_set:\n","                uniq_speaker = speaker_set.index(speaker)\n","            else:\n","                speaker_set.append(speaker)\n","                uniq_speaker = speaker_set.index(speaker)\n","            emotion = line[emo_idx]\n","            sess = line[sess_idx]\n","            \n","            if pre_sess == 'start' or sess == pre_sess:\n","                session.append([uniq_speaker, utt, emotion])\n","            else:\n","                \"\"\" 세션 데이터 저장 \"\"\"\n","                # session_dataset.append(session)\n","                session_dataset += split(session)\n","                session = [[uniq_speaker, utt, emotion]]\n","                speaker_set = []\n","            pre_sess = sess   \n","    \"\"\" 마지막 세션 저장 \"\"\"\n","    # session_dataset.append(session)\n","    session_dataset += split(session)\n","    f.close()\n","    \n","    \"\"\" 데이터 분할하기 \"\"\"\n","    break"]},{"cell_type":"code","execution_count":10,"id":"5e85a760-bc38-4a80-929b-eb47bee4d0c3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5e85a760-bc38-4a80-929b-eb47bee4d0c3","executionInfo":{"status":"ok","timestamp":1663995437693,"user_tz":-540,"elapsed":4,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"56f6acd5-57bc-4afb-cc0f-e93828651464"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0,\n","  'also I was the point person on my company’s transition from the KL-5 to GR-6 system.',\n","  'neutral']]"]},"metadata":{},"execution_count":10}],"source":["session_dataset[0]"]},{"cell_type":"code","execution_count":11,"id":"1f7fec40-2166-43c1-b151-b9dc2803778d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1f7fec40-2166-43c1-b151-b9dc2803778d","executionInfo":{"status":"ok","timestamp":1663995438189,"user_tz":-540,"elapsed":3,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"2be6b952-63fd-4f61-ef25-30e97528068b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[0,\n","  'also I was the point person on my company’s transition from the KL-5 to GR-6 system.',\n","  'neutral'],\n"," [1, 'You must’ve had your hands full.', 'neutral'],\n"," [0, 'That I did. That I did.', 'neutral'],\n"," [1, 'So let’s talk a little bit about your duties.', 'neutral'],\n"," [0, 'My duties?  All right.', 'surprise'],\n"," [1,\n","  'Now you’ll be heading a whole division, so you’ll have a lot of duties.',\n","  'neutral']]"]},"metadata":{},"execution_count":11}],"source":["session_dataset[5]"]},{"cell_type":"markdown","id":"882b155b-68b8-4814-a70e-da34a30bcde8","metadata":{"id":"882b155b-68b8-4814-a70e-da34a30bcde8"},"source":["## 실제 감정인식에 맞게 데이터 분할하기 (배치처리 알아보기)\n"]},{"cell_type":"code","execution_count":12,"id":"a5c751e4-d4cf-4525-80c1-75529c04d635","metadata":{"id":"a5c751e4-d4cf-4525-80c1-75529c04d635","executionInfo":{"status":"ok","timestamp":1663995439712,"user_tz":-540,"elapsed":3,"user":{"displayName":"이주성","userId":"05491312179909265297"}}},"outputs":[],"source":["import csv\n","from torch.utils.data import Dataset\n","def split(session):\n","    final_data = []\n","    split_session = []\n","    for line in session:\n","        split_session.append(line)\n","        final_data.append(split_session[:])    \n","    return final_data\n","\n","class data_loader(Dataset):\n","    def __init__(self, data_path):\n","        f = open(data_path, 'r')\n","        rdr = csv.reader(f)\n","        \n","        \"\"\" 추가 \"\"\"\n","        emoSet = set()\n","\n","        \"\"\" 세션 데이터 저장할 것\"\"\"\n","        self.session_dataset = []\n","        session = []\n","        speaker_set = []\n","\n","        \"\"\" 실제 데이터 저장 방식 \"\"\"\n","        pre_sess = 'start'\n","        for i, line in enumerate(rdr):\n","            if i == 0:\n","                \"\"\" 저장할 데이터들 index 확인 \"\"\"\n","                header  = line\n","                utt_idx = header.index('Utterance')\n","                speaker_idx = header.index('Speaker')\n","                emo_idx = header.index('Emotion')\n","                sess_idx = header.index('Dialogue_ID')\n","            else:\n","                utt = line[utt_idx]\n","                speaker = line[speaker_idx]\n","                \"\"\" 유니크한 스피커로 바꾸기 \"\"\"\n","                if speaker in speaker_set:\n","                    uniq_speaker = speaker_set.index(speaker)\n","                else:\n","                    speaker_set.append(speaker)\n","                    uniq_speaker = speaker_set.index(speaker)\n","                emotion = line[emo_idx]\n","                sess = line[sess_idx]\n","\n","                if pre_sess == 'start' or sess == pre_sess:\n","                    session.append([uniq_speaker, utt, emotion])\n","                else:\n","                    \"\"\" 세션 데이터 저장 \"\"\"\n","                    self.session_dataset += split(session)\n","                    session = [[uniq_speaker, utt, emotion]]\n","                    speaker_set = []\n","                    emoSet.add(emotion)\n","                pre_sess = sess   \n","        \"\"\" 마지막 세션 저장 \"\"\"\n","        self.session_dataset += split(session)\n","            \n","        \"\"\" 추가 \"\"\"\n","        # self.emoList = sorted(emoSet) # 항상 같은 레이블 순서를 유지하기 위해\n","        self.emoList = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n","        f.close()\n","        \n","    def __len__(self): # 기본적인 구성\n","        return len(self.session_dataset)\n","    \n","    def __getitem__(self, idx): # 기본적인 구성\n","        return self.session_dataset[idx]\n","    \n","    def collate_fn(self, sessions): # 배치를 위한 구성\n","        '''\n","            input:\n","                data: [(session1), (session2), ... ]\n","            return:\n","                batch_input_tokens_pad: (B, L) padded\n","                batch_labels: (B)\n","        '''\n","        batch_input_token = []\n","        for session in sessions:\n","            input_token = \"\"\n","            for line in session:\n","                speaker, utt, emotion = line\n","                input_token += utt\n","            batch_input_token.append(input_token)\n","        \n","        return batch_input_token"]},{"cell_type":"code","execution_count":13,"id":"09a4c29e-d428-48b0-bbdd-8f5b803410ad","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"09a4c29e-d428-48b0-bbdd-8f5b803410ad","executionInfo":{"status":"ok","timestamp":1663995441875,"user_tz":-540,"elapsed":5,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"f01a600f-d898-4842-e1b3-86a80eb06e97"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["([[0, 'Oh my God, he’s lost it. He’s totally lost it.', 'sadness']],\n"," [[0, 'Oh my God, he’s lost it. He’s totally lost it.', 'sadness'],\n","  [1, 'What?', 'surprise']])"]},"metadata":{},"execution_count":13}],"source":["dev_dataset = data_loader('./MELD/data/MELD/dev_sent_emo.csv')\n","dev_dataset[0], dev_dataset[1]"]},{"cell_type":"code","execution_count":14,"id":"37344d6c-ea56-49c1-808d-e06e0cfce1bd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37344d6c-ea56-49c1-808d-e06e0cfce1bd","executionInfo":{"status":"ok","timestamp":1663995441876,"user_tz":-540,"elapsed":4,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"69aad11f-c913-48b3-8e99-d3fe67d0b2fe"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["0 ['Oh my God, he’s lost it. He’s totally lost it.']\n","1 ['Oh my God, he’s lost it. He’s totally lost it.What?']\n","2 ['Or! Or, we could go to the bank, close our accounts and cut them off at the source.']\n"]}],"source":["\"\"\" 배치 결과 확인 \"\"\"\n","from torch.utils.data import DataLoader\n","dev_dataloader = DataLoader(dev_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n","\n","i = 0\n","for data in dev_dataloader:\n","    print(i, data)\n","    i += 1\n","    if i > 2:\n","        break    "]},{"cell_type":"code","execution_count":15,"id":"31598e80-7283-4bef-8141-37e05bf1a7dd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31598e80-7283-4bef-8141-37e05bf1a7dd","executionInfo":{"status":"ok","timestamp":1663995443386,"user_tz":-540,"elapsed":3,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"922f11dc-9db3-4949-e5a5-5a9bc00e6d76"},"outputs":[{"output_type":"stream","name":"stdout","text":["Oh my God, he’s lost it. He’s totally lost it.\n","Oh my God, he’s lost it. He’s totally lost it.What?\n","Or! Or, we could go to the bank, close our accounts and cut them off at the source.\n"]}],"source":["\"\"\" 배치 결과 확인 \"\"\"\n","from torch.utils.data import DataLoader\n","dev_dataloader = DataLoader(dev_dataset, batch_size=3, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n","\n","for data in dev_dataloader:\n","    print(data[0])\n","    print(data[1])\n","    print(data[2])\n","    break"]},{"cell_type":"markdown","id":"fbf86abb-179a-48d0-b427-8f47144bbac1","metadata":{"id":"fbf86abb-179a-48d0-b427-8f47144bbac1"},"source":["## 사전 학습 모델들에 대한 백그라운드"]},{"cell_type":"code","execution_count":16,"id":"b91888f4-0700-46ca-b977-22a579738b52","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["4a67d2a5a2b8497e978941315e73ee57","9bdd70ccdd3e4e2e908ea7934350c30d","a6ce41255b454c08b96dd7eb05a44641","fc8dd8e8e38842678b009fbf2af1ca86","3bbf238354dc4aa88fdb7fae8da2c473","3dd949c5b75c4d108b7bbe44460c56cf","e8be32bd5baf43ae93eef123dd5a042f","982341076c7e462c8d88752531e3d7fd","63c1a6ff1488408489875f83c88bf540","6000a3950b9f47de95046e894255c27d","d844a2b9c9334c11bb909b2be9682d55","a54b8f39ad84433f8cf5f70456b86fc1","afd9c10670434e9999dbd495ed53fab9","ebbc39fe81324996a42cb3819ad582c0","372da0def3e64334adb67e9582802ff9","d9547e48fc6b4d5db9a27f112241be90","a703cb42a6c9406599aeb9d59e84bead","2a77f20be08f485f835a36344d2f14af","a345546660af4090aadda2ab60079584","da5c999b5e6d4898930b22a37cd56ea0","fa8ea8931b2144748e5eb8615bb1134c","6675f8e717554f3abdb0b8b132798165","181b177cb9c24073a23f66c1633d54fc","c469069e97014e38b08c19e407b62c3b","87c6ba6b21da4920b9c11e96bca61d9c","0ca6cbdc7ecd45fb965a06b503e6431b","a24f3b696817480d86aa63a36130f516","76a84ecdf66b48ceaf4a39b9d7c635c0","b8eb05407a684b9299a688bf0d9115dd","b4f3416d7b30467db737c2b861499504","cbebf21792724ee9bc2753c2dade04c6","9226cb4723eb456292570d29c5b85b66","0ed7c78cb6cf41ffb3c05fe313fdfea3"]},"id":"b91888f4-0700-46ca-b977-22a579738b52","executionInfo":{"status":"ok","timestamp":1663995459022,"user_tz":-540,"elapsed":12666,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"89a95c08-7c1c-463d-d06a-6fc0aba15cbe"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a67d2a5a2b8497e978941315e73ee57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a54b8f39ad84433f8cf5f70456b86fc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"181b177cb9c24073a23f66c1633d54fc"}},"metadata":{}}],"source":["\"\"\" 토크나이저 확인하기 \"\"\"\n","# https://github.com/thunlp/PLMpapers\n","from transformers import RobertaTokenizer\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"]},{"cell_type":"code","execution_count":17,"id":"679acdac-eab9-4ad8-bb7f-06ef74edd394","metadata":{"id":"679acdac-eab9-4ad8-bb7f-06ef74edd394","executionInfo":{"status":"ok","timestamp":1663995459022,"user_tz":-540,"elapsed":10,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1e3a82ca-843e-4ade-a3f2-bdf9e16e67bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["<s> </s> <pad>\n","0 2 1\n"]}],"source":["print(tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token)\n","print(tokenizer.cls_token_id, tokenizer.sep_token_id, tokenizer.pad_token_id)"]},{"cell_type":"code","source":["input_str1 = \"<s> 안녕하세요 </s> 무슨 일인가요? <pad> <pad> <pad> <pad> ...\"\n","input_str2 = \"<s> 안녕하세요 </s> 무슨 일인가요? </s> 아무일 없습니다.\""],"metadata":{"id":"bgOhsgJnY52N","executionInfo":{"status":"ok","timestamp":1663995459023,"user_tz":-540,"elapsed":8,"user":{"displayName":"이주성","userId":"05491312179909265297"}}},"id":"bgOhsgJnY52N","execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":19,"id":"fdd63040-071a-4b48-8d48-acd28fa87ea4","metadata":{"id":"fdd63040-071a-4b48-8d48-acd28fa87ea4","executionInfo":{"status":"ok","timestamp":1663995459023,"user_tz":-540,"elapsed":8,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9747cec2-7fc7-4206-c5cf-bbda3525bf22"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["512"]},"metadata":{},"execution_count":19}],"source":["# dir(tokenizer)\n","tokenizer.model_max_length"]},{"cell_type":"code","execution_count":20,"id":"76b4da6a-173c-4a0d-a6b5-f4e2ca6638c0","metadata":{"id":"76b4da6a-173c-4a0d-a6b5-f4e2ca6638c0","executionInfo":{"status":"ok","timestamp":1663995459023,"user_tz":-540,"elapsed":6,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c863b5df-4902-43bb-ca91-f5bb291e26b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [0, 42891, 4, 42, 16, 1769, 28135, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n","[0, 42891, 4, 42, 16, 1769, 28135, 2]\n","{'input_ids': [[0, 42891, 4, 42, 16, 1769, 28135, 2], [0, 12196, 32, 47, 608, 116, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}\n","{'input_ids': [[42891, 4, 42, 16, 1769, 28135], [12196, 32, 47, 608, 116]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}\n"]}],"source":["\"\"\" 토크나이저 작동 \"\"\"\n","res = tokenizer('hello. this is fastcampus')\n","print(res)\n","res = tokenizer.encode('hello. this is fastcampus')\n","print(res)\n","res = tokenizer(['hello. this is fastcampus', \"what are you doing?\"])\n","print(res)\n","res = tokenizer(['hello. this is fastcampus', \"what are you doing?\"], add_special_tokens=False)\n","print(res)"]},{"cell_type":"code","execution_count":21,"id":"9fb86d18-0411-4ff2-b086-e740a83e5e1b","metadata":{"id":"9fb86d18-0411-4ff2-b086-e740a83e5e1b","executionInfo":{"status":"ok","timestamp":1663995459023,"user_tz":-540,"elapsed":5,"user":{"displayName":"이주성","userId":"05491312179909265297"}}},"outputs":[],"source":["\"\"\" 배치 입력 토큰들 처리 \"\"\"\n","from torch.utils.data import Dataset\n","from transformers import RobertaTokenizer\n","import csv\n","from torch.utils.data import Dataset\n","import torch\n","\n","def split(session):\n","    final_data = []\n","    split_session = []\n","    for line in session:\n","        split_session.append(line)\n","        final_data.append(split_session[:])    \n","    return final_data\n","\n","class data_loader(Dataset):\n","    def __init__(self, data_path):\n","        f = open(data_path, 'r')\n","        rdr = csv.reader(f)\n","        \n","        \"\"\" 추가 \"\"\"\n","        emoSet = set()\n","        self.tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","\n","        \"\"\" 세션 데이터 저장할 것\"\"\"\n","        self.session_dataset = []\n","        session = []\n","        speaker_set = []\n","\n","        \"\"\" 실제 데이터 저장 방식 \"\"\"\n","        pre_sess = 'start'\n","        for i, line in enumerate(rdr):\n","            if i == 0:\n","                \"\"\" 저장할 데이터들 index 확인 \"\"\"\n","                header  = line\n","                utt_idx = header.index('Utterance')\n","                speaker_idx = header.index('Speaker')\n","                emo_idx = header.index('Emotion')\n","                sess_idx = header.index('Dialogue_ID')\n","            else:\n","                utt = line[utt_idx]\n","                speaker = line[speaker_idx]\n","                \"\"\" 유니크한 스피커로 바꾸기 \"\"\"\n","                if speaker in speaker_set:\n","                    uniq_speaker = speaker_set.index(speaker)\n","                else:\n","                    speaker_set.append(speaker)\n","                    uniq_speaker = speaker_set.index(speaker)\n","                emotion = line[emo_idx]\n","                sess = line[sess_idx]\n","\n","                if pre_sess == 'start' or sess == pre_sess:\n","                    session.append([uniq_speaker, utt, emotion])\n","                else:\n","                    \"\"\" 세션 데이터 저장 \"\"\"\n","                    self.session_dataset += split(session)\n","                    session = [[uniq_speaker, utt, emotion]]\n","                    speaker_set = []\n","                    emoSet.add(emotion)\n","                pre_sess = sess   \n","        \"\"\" 마지막 세션 저장 \"\"\"\n","        self.session_dataset += split(session)\n","            \n","        # self.emoList = sorted(emoSet) # 항상 같은 레이블 순서를 유지하기 위해\n","        self.emoList = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n","        f.close()\n","        \n","    def __len__(self): # 기본적인 구성\n","        return len(self.session_dataset)\n","    \n","    def __getitem__(self, idx): # 기본적인 구성\n","        return self.session_dataset[idx]\n","    \n","    def padding(self, batch_input_token):\n","        \"\"\" 추가 \"\"\"\n","        \"\"\" 512 토큰 길이 넘으면 잘라내기 \"\"\"\n","        batch_token_ids, batch_attention_masks = batch_input_token['input_ids'], batch_input_token['attention_mask']\n","        trunc_batch_token_ids, trunc_batch_attention_masks = [], []\n","        for batch_token_id, batch_attention_mask in zip(batch_token_ids, batch_attention_masks):\n","            if len(batch_token_id) > self.tokenizer.model_max_length:\n","                trunc_batch_token_id = [batch_token_id[0]] + batch_token_id[1:][-self.tokenizer.model_max_length+1:]\n","                trunc_batch_attention_mask = [batch_attention_mask[0]] + batch_attention_mask[1:][-self.tokenizer.model_max_length+1:]\n","                trunc_batch_token_ids.append(trunc_batch_token_id)\n","                trunc_batch_attention_masks.append(trunc_batch_attention_mask)\n","            else:\n","                trunc_batch_token_ids.append(batch_token_id)\n","                trunc_batch_attention_masks.append(batch_attention_mask)\n","        \n","        \"\"\" padding token으로 패딩하기 \"\"\"\n","        # [10, 30, 50]\n","        # [50, 50, 50] \n","        # 50-10=40 , 50-30=20 : 패딩토큰으로 채운다. <pad>\n","        max_length = max([len(x) for x in trunc_batch_token_ids])\n","        padding_tokens, padding_attention_masks = [], []\n","        for batch_token_id, batch_attention_mask in zip(trunc_batch_token_ids, trunc_batch_attention_masks):\n","            padding_tokens.append(batch_token_id + [self.tokenizer.pad_token_id for _ in range(max_length-len(batch_token_id))])\n","            padding_attention_masks.append(batch_attention_mask + [0 for _ in range(max_length-len(batch_token_id))]                                                        )\n","        return torch.tensor(padding_tokens), torch.tensor(padding_attention_masks)\n","    \n","    def collate_fn(self, sessions): # 배치를 위한 구성\n","        '''\n","            input:\n","                data: [(session1), (session2), ... ]\n","            return:\n","                batch_input_tokens_pad: (B, L) padded\n","                batch_labels: (B)\n","        '''\n","        ## [발화1, 발화2, ..., 발화8]\n","        # 발화1~발화7 컨텍스트로 사용한다면 입력이 길어진다.\n","        # 발화1 같은 경우는 발화8에 덜중요할거에요.\n","        # 적절하게 컨텍스트 길이를 조절해도된다.\n","        # 3개로 정한다면, [발화5,발화6,발화7,발화8]\n","        \"\"\" 추가 \"\"\"\n","        batch_input, batch_labels = [], []\n","        batch_PM_input = []\n","        for session in sessions:\n","            input_str = self.tokenizer.cls_token\n","            \n","            \"\"\" For PM \"\"\"\n","            current_speaker, current_utt, current_emotion = session[-1]\n","            PM_input = []\n","            for i, line in enumerate(session):\n","                speaker, utt, emotion = line\n","                input_str += \" \" + utt + self.tokenizer.sep_token\n","                if i < len(session)-1 and current_speaker == speaker:\n","                    PM_input.append(self.tokenizer.encode(utt, add_special_tokens=True, return_tensors='pt'))\n","                    # [cls_token, tokens, sep_token]\n","                    \n","            \"\"\" For CoM \"\"\"\n","            batch_input.append(input_str)\n","            batch_labels.append(self.emoList.index(emotion))\n","            batch_PM_input.append(PM_input)\n","        batch_input_token = self.tokenizer(batch_input, add_special_tokens=False)\n","        batch_padding_token, batch_padding_attention_mask = self.padding(batch_input_token)\n","        \n","        return batch_padding_token, batch_padding_attention_mask, batch_PM_input, torch.tensor(batch_labels)"]},{"cell_type":"code","source":[],"metadata":{"id":"toF19eMdcevJ"},"id":"toF19eMdcevJ","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":22,"id":"82f61747-acc4-44c7-8330-7fa798edb4b0","metadata":{"id":"82f61747-acc4-44c7-8330-7fa798edb4b0","executionInfo":{"status":"ok","timestamp":1663995465602,"user_tz":-540,"elapsed":5869,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"92e4d494-cfcc-471d-96fd-e9fe655f5f10"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 58])\n","batch_padding_token tensor([[    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n","           827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n","             5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n","           328,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1,     1,     1,     1,     1,     1,     1],\n","        [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n","           827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n","             5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n","           328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n","            17,    27,    90,    28,   827, 30489,   328,     2,     1,     1,\n","             1,     1,     1,     1,     1,     1,     1,     1],\n","        [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n","           827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n","             5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n","           328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n","            17,    27,    90,    28,   827, 30489,   328,     2,   978,     6,\n","            89,    17,    27,    29,    80,  2188,     4,     2]])\n","batch_padding_attention_mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","batch_PM_input [[], [], [tensor([[    0,  1185,    17,    27,   241,    10, 16333,   328,     2]])]]\n","batch_label tensor([3, 5, 4])\n"]}],"source":["\"\"\" 배치 결과 확인 \"\"\"\n","from torch.utils.data import DataLoader\n","dev_dataset = data_loader('./MELD/data/MELD/dev_sent_emo.csv')\n","dev_dataloader = DataLoader(dev_dataset, batch_size=3, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n","\n","for i, data in enumerate(dev_dataloader):\n","    if i == 1:\n","        print(data[0].shape)\n","        batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n","        print(\"batch_padding_token\", batch_padding_token)\n","        print(\"batch_padding_attention_mask\", batch_padding_attention_mask)\n","        print(\"batch_PM_input\", batch_PM_input)\n","        print(\"batch_label\", batch_label)\n","        break"]},{"cell_type":"markdown","id":"247d15b2-5cc0-4855-b3cd-5f7ce3a9526f","metadata":{"id":"247d15b2-5cc0-4855-b3cd-5f7ce3a9526f"},"source":["## 파일로 저장하기"]},{"cell_type":"code","execution_count":23,"id":"fe348aa3-ee51-4249-86bd-444ed7271507","metadata":{"id":"fe348aa3-ee51-4249-86bd-444ed7271507","executionInfo":{"status":"ok","timestamp":1663995636513,"user_tz":-540,"elapsed":1047,"user":{"displayName":"이주성","userId":"05491312179909265297"}}},"outputs":[],"source":["!touch dataset.py\n","# 코드 복사하기"]},{"cell_type":"code","execution_count":24,"id":"1b5d501b-859a-4d1f-b1ab-9defd25a99ba","metadata":{"id":"1b5d501b-859a-4d1f-b1ab-9defd25a99ba","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663995705722,"user_tz":-540,"elapsed":6006,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"883428b7-5ff1-492e-9b31-0bc5b6003d5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 58])\n","batch_padding_token tensor([[    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n","           827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n","             5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n","           328,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1,     1,     1,     1,     1,     1,     1],\n","        [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n","           827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n","             5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n","           328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n","            17,    27,    90,    28,   827, 30489,   328,     2,     1,     1,\n","             1,     1,     1,     1,     1,     1,     1,     1],\n","        [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n","           827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n","             5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n","           328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n","            17,    27,    90,    28,   827, 30489,   328,     2,   978,     6,\n","            89,    17,    27,    29,    80,  2188,     4,     2]])\n","batch_padding_attention_mask tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","batch_PM_input [[], [], [tensor([[    0,  1185,    17,    27,   241,    10, 16333,   328,     2]])]]\n","batch_label tensor([3, 5, 4])\n"]}],"source":["from dataset import data_loader\n","from torch.utils.data import DataLoader\n","dev_dataset = data_loader('./MELD/data/MELD/dev_sent_emo.csv')\n","dev_dataloader = DataLoader(dev_dataset, batch_size=3, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n","\n","for i, data in enumerate(dev_dataloader):\n","    if i == 1:\n","        print(data[0].shape)\n","        batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n","        print(\"batch_padding_token\", batch_padding_token)\n","        print(\"batch_padding_attention_mask\", batch_padding_attention_mask)\n","        print(\"batch_PM_input\", batch_PM_input)\n","        print(\"batch_label\", batch_label)\n","        break"]},{"cell_type":"markdown","id":"5695ff85-38a1-44fb-b73c-df0e3d683ae4","metadata":{"id":"5695ff85-38a1-44fb-b73c-df0e3d683ae4"},"source":["# **사전학습 모델 불러와서 로딩하기**"]},{"cell_type":"code","execution_count":26,"id":"8031a064-0837-4137-997a-07a648d72f17","metadata":{"id":"8031a064-0837-4137-997a-07a648d72f17","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663996104694,"user_tz":-540,"elapsed":4425,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"3621100d-c6e7-4cc3-d7d9-41453ded9732"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}],"source":["from transformers import RobertaModel\n","model = RobertaModel.from_pretrained('roberta-base')\n","print('')"]},{"cell_type":"code","source":["# model\n","dir(model)"],"metadata":{"id":"7WjSum3uGRyE"},"id":"7WjSum3uGRyE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.train() # dropout의 probability을 이용한다\n","# 학습코드\n","model.eval() # dropout의 probability을 이용한다 --> dropout 작동X\n","# 평가코드"],"metadata":{"id":"MS1wlLz1D2fs"},"id":"MS1wlLz1D2fs","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 사전학습 모델 사용해보기"],"metadata":{"id":"qztkbqmGZiY3"},"id":"qztkbqmGZiY3"},{"cell_type":"code","source":["batch_padding_token.shape, batch_padding_attention_mask.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8vgufcGHSM1","executionInfo":{"status":"ok","timestamp":1663996700289,"user_tz":-540,"elapsed":1054,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"a030c24f-941e-4f74-da11-869506f5866f"},"id":"-8vgufcGHSM1","execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([3, 58]), torch.Size([3, 58]))"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["batch_padding_token, batch_padding_attention_mask"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecachU2YeSK-","executionInfo":{"status":"ok","timestamp":1663996705010,"user_tz":-540,"elapsed":459,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"0628b8f4-f840-4ba6-bb76-673e972f1094"},"id":"ecachU2YeSK-","execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n","            827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n","              5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n","            328,     2,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1],\n","         [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n","            827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n","              5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n","            328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n","             17,    27,    90,    28,   827, 30489,   328,     2,     1,     1,\n","              1,     1,     1,     1,     1,     1,     1,     1],\n","         [    0,  1793,   328,  1793,     6,    52,   115,   213,     7,     5,\n","            827,     6,   593,    84,  2349,     8,   847,   106,   160,    23,\n","              5,  1300,     4,     2,   370,    17,    27,   241,    10, 16333,\n","            328,     2,    83, 33130,     6,   313,     6,   122,    52,   351,\n","             17,    27,    90,    28,   827, 30489,   328,     2,   978,     6,\n","             89,    17,    27,    29,    80,  2188,     4,     2]]),\n"," tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]))"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","execution_count":38,"id":"494aa28b-41dc-470b-ae6d-aebc3cff3bbf","metadata":{"id":"494aa28b-41dc-470b-ae6d-aebc3cff3bbf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663997448448,"user_tz":-540,"elapsed":3,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"ae319f52-c46d-4115-f9fc-913f7f6c7ed6"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 58, 768])\n","torch.Size([3, 768])\n"]}],"source":["\"\"\" for CoM \"\"\"\n","batch_com_out = model(input_ids=batch_padding_token, attention_mask=batch_padding_attention_mask)['last_hidden_state']\n","print(batch_com_out.shape)\n","batch_com_final = batch_com_out[:,0,:] # CLS 토큰의 output 가져오기 위해\n","print(batch_com_final.shape)"]},{"cell_type":"code","source":["# result = model(input_ids=batch_padding_token, attention_mask=batch_padding_attention_mask)\n","# result.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSCZFHtD64u6","executionInfo":{"status":"ok","timestamp":1663996763557,"user_tz":-540,"elapsed":491,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"dfd9663a-83ef-43e5-ae3b-d5cac182ca9e"},"id":"aSCZFHtD64u6","execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["odict_keys(['last_hidden_state', 'pooler_output'])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["batch_PM_input"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yw8DYw6o8pG-","executionInfo":{"status":"ok","timestamp":1663996959313,"user_tz":-540,"elapsed":777,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"93742bff-eb1d-4138-c04e-1ac3ecb010cc"},"id":"Yw8DYw6o8pG-","execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[],\n"," [],\n"," [tensor([[    0,  1185,    17,    27,   241,    10, 16333,   328,     2]])]]"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","execution_count":31,"id":"1acb48d6-a7de-411a-b72c-fdccf1b61b23","metadata":{"id":"1acb48d6-a7de-411a-b72c-fdccf1b61b23","executionInfo":{"status":"ok","timestamp":1663996381610,"user_tz":-540,"elapsed":4404,"user":{"displayName":"이주성","userId":"05491312179909265297"}}},"outputs":[],"source":["import torch\n","\n","model2 = RobertaModel.from_pretrained('roberta-base')\n","# 발화1: feature1 [1, 768]\n","# 발화3: feature3 [1, 768]\n","# 발화6에 해당하는 감정을 예측할 때 발화1, 발화3의 정보를 사용할 것\n","# feature1 + feature3\n","# (feature1, feature6) 어텐션 weights w1\n","# (feature3, feature6) 어텐션 weights w3\n","# w1*feature1 + w3*feature6\n","# GRU(feature1, feature3)\n","\n","\"\"\" GRU 세팅 \"\"\"\n","import torch.nn as nn \n","hiddenDim = model2.config.hidden_size\n","zero = torch.empty(2, 1, hiddenDim)\n","h0 = torch.zeros_like(zero) # (num_layers * num_directions, batch, hidden_size)\n","speakerGRU = nn.GRU(hiddenDim, hiddenDim, 2, dropout=0.3) # (input, hidden, num_layer) (BERT_emb, BERT_emb, num_layer)\n","\n","\"\"\" GRU 통과 --> PM 결과 \"\"\"\n","batch_pm_gru_final = []\n","for PM_inputs in batch_PM_input:\n","    if PM_inputs:\n","        pm_outs = []\n","        for PM_input in PM_inputs:\n","            pm_out = model2(PM_input)['last_hidden_state'][:,0,:] # CLS의 출력\n","            pm_outs.append(pm_out)\n","        pm_outs = torch.cat(pm_outs, 0).unsqueeze(1) # (speaker_num, batch=1, hidden_dim)\n","        pm_gru_outs, _ = speakerGRU(pm_outs, h0) # (speaker_num, batch=1, hidden_dim)\n","        pm_gru_final = pm_gru_outs[-1,:,:] # (1, hidden_dim)\n","        batch_pm_gru_final.append(pm_gru_final)\n","    else:\n","        batch_pm_gru_final.append(torch.zeros(1, hiddenDim))\n","batch_pm_gru_final = torch.cat(batch_pm_gru_final, 0)"]},{"cell_type":"code","execution_count":32,"id":"57e98f3e-da59-4403-9752-44015f7acbe0","metadata":{"id":"57e98f3e-da59-4403-9752-44015f7acbe0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663996381610,"user_tz":-540,"elapsed":5,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"dea53925-c6fd-4c98-9afa-ea3dcf6bcbe2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 768])"]},"metadata":{},"execution_count":32}],"source":["batch_pm_gru_final.shape"]},{"cell_type":"markdown","source":["## 추가적인 layer 구성하기"],"metadata":{"id":"53UFgw2LcmIl"},"id":"53UFgw2LcmIl"},{"cell_type":"code","execution_count":39,"id":"d6702a8d-eca6-4341-9e3f-3c67fbe69901","metadata":{"id":"d6702a8d-eca6-4341-9e3f-3c67fbe69901","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663997453654,"user_tz":-540,"elapsed":2,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"cd3a9e04-55ff-4cbb-cc7c-fa4255f3faee"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 7])\n"]}],"source":["\"\"\" score matrix \"\"\"\n","clsNum = len(dev_dataset.emoList)\n","W = nn.Linear(hiddenDim, clsNum)\n","final_output = W(batch_com_final + batch_pm_gru_final)\n","print(final_output.shape) # (B, C)"]},{"cell_type":"code","execution_count":40,"id":"95e37966-5aec-43cc-ae1b-4d89654587fe","metadata":{"id":"95e37966-5aec-43cc-ae1b-4d89654587fe","executionInfo":{"status":"ok","timestamp":1663997458554,"user_tz":-540,"elapsed":821,"user":{"displayName":"이주성","userId":"05491312179909265297"}}},"outputs":[],"source":["from transformers import RobertaModel\n","import torch\n","import torch.nn as nn\n","\n","class ERC_model(nn.Module):\n","    def __init__(self, clsNum):\n","        super(ERC_model, self).__init__()\n","        self.com_model = RobertaModel.from_pretrained('roberta-base')\n","        self.pm_model = RobertaModel.from_pretrained('roberta-base')\n","        \n","        \"\"\" GRU 세팅 \"\"\"\n","        self.hiddenDim = self.com_model.config.hidden_size\n","        zero = torch.empty(2, 1, self.hiddenDim)\n","        self.h0 = torch.zeros_like(zero) # (num_layers * num_directions, batch, hidden_size)\n","        self.speakerGRU = nn.GRU(self.hiddenDim, self.hiddenDim, 2, dropout=0.3) # (input, hidden, num_layer) (BERT_emb, BERT_emb, num_layer)\n","        \n","        \"\"\" score matrix \"\"\"\n","        self.W = nn.Linear(self.hiddenDim, clsNum)\n","    def forward(self, batch_padding_token, batch_padding_attention_mask, batch_PM_input):\n","        \"\"\" for CoM \"\"\"\n","        batch_com_out = self.com_model(input_ids=batch_padding_token, attention_mask=batch_padding_attention_mask)['last_hidden_state']\n","        batch_com_final = batch_com_out[:,0,:]\n","        \n","        \"\"\" GRU 통과 --> PM 결과 \"\"\"\n","        batch_pm_gru_final = []\n","        for PM_inputs in batch_PM_input:\n","            if PM_inputs:\n","                pm_outs = []\n","                for PM_input in PM_inputs:\n","                    pm_out = self.pm_model(PM_input)['last_hidden_state'][:,0,:]\n","                    pm_outs.append(pm_out)\n","                pm_outs = torch.cat(pm_outs, 0).unsqueeze(1) # (speaker_num, batch=1, hidden_dim)\n","                pm_gru_outs, _ = self.speakerGRU(pm_outs, self.h0) # (speaker_num, batch=1, hidden_dim)\n","                pm_gru_final = pm_gru_outs[-1,:,:] # (1, hidden_dim)\n","                batch_pm_gru_final.append(pm_gru_final)\n","            else:\n","                batch_pm_gru_final.append(torch.zeros(1, self.hiddenDim))\n","        batch_pm_gru_final = torch.cat(batch_pm_gru_final, 0)        \n","        \n","        \"\"\" score matrix \"\"\"\n","        final_output = self.W(batch_com_final + batch_pm_gru_final) # (B, C)\n","        \n","        return final_output"]},{"cell_type":"code","execution_count":41,"id":"7e95ddee-488d-4036-9159-95a25794d251","metadata":{"id":"7e95ddee-488d-4036-9159-95a25794d251","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663997467688,"user_tz":-540,"elapsed":8483,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"d6abbdd7-6b5a-4429-82b6-5b75b72dbfb8"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([3, 7])\n"]}],"source":["clsNum = len(dev_dataset.emoList)\n","model = ERC_model(clsNum)\n","result = model(batch_padding_token, batch_padding_attention_mask, batch_PM_input)\n","print(result.shape)"]},{"cell_type":"markdown","id":"4eba9cfc-edf9-43ba-8864-e205ccfef127","metadata":{"id":"4eba9cfc-edf9-43ba-8864-e205ccfef127"},"source":["## 파일로 저장하기"]},{"cell_type":"code","execution_count":42,"id":"4326fc82-ba1e-411c-9f44-5d492fb2836e","metadata":{"id":"4326fc82-ba1e-411c-9f44-5d492fb2836e","executionInfo":{"status":"ok","timestamp":1663997842014,"user_tz":-540,"elapsed":475,"user":{"displayName":"이주성","userId":"05491312179909265297"}}},"outputs":[],"source":["!touch model.py\n","# 코드 복사하기"]},{"cell_type":"markdown","id":"cbec9d73-20f4-4f07-a532-8d4ffb491ea4","metadata":{"id":"cbec9d73-20f4-4f07-a532-8d4ffb491ea4"},"source":["# **학습 코드 짜기**"]},{"cell_type":"markdown","source":["## 평가 설명하기"],"metadata":{"id":"_xg9fegBKwnk"},"id":"_xg9fegBKwnk"},{"cell_type":"code","source":["import torch\n","from tqdm import tqdm\n","def CalACC(model, dataloader):\n","    model.eval()\n","    correct = 0\n","    label_list = []\n","    pred_list = []\n","    \n","    # label arragne\n","    with torch.no_grad():\n","        for i_batch, data in enumerate(tqdm(dataloader)):\n","            \"\"\"Prediction\"\"\"\n","            batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n","            batch_padding_token = batch_padding_token.cuda()\n","            batch_padding_attention_mask = batch_padding_attention_mask.cuda()\n","            batch_PM_input = [[x2.cuda() for x2 in x1] for x1 in batch_PM_input]\n","            batch_label = batch_label.cuda()        \n","\n","            \"\"\"Prediction\"\"\"\n","            pred_logits = erc_model(batch_padding_token, batch_padding_attention_mask, batch_PM_input)\n","            \n","            \"\"\"Calculation\"\"\"    \n","            pred_label = pred_logits.argmax(1).item()\n","            true_label = batch_label.item()\n","            \n","            pred_list.append(pred_label)\n","            label_list.append(true_label)\n","            if pred_label == true_label:\n","                correct += 1\n","        acc = correct/len(dataloader)\n","    return acc, pred_list, label_list"],"metadata":{"id":"peWifomMKxfl"},"id":"peWifomMKxfl","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_fscore_support\n","dev_acc, dev_pred_list, dev_label_list = CalACC(erc_model, dev_dataloader)\n","dev_pre, dev_rec, dev_fbeta, _ = precision_recall_fscore_support(dev_label_list, dev_pred_list, average='weighted')"],"metadata":{"id":"e1HFz0wnK0zE"},"id":"e1HFz0wnK0zE","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"a80628fd-c170-4eab-979b-9c8d1c0c77ee","metadata":{"id":"a80628fd-c170-4eab-979b-9c8d1c0c77ee","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662191402729,"user_tz":-540,"elapsed":2155,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"52827b71-a7c6-4cbd-87e4-caf61c1f7584"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}],"source":["from dataset import data_loader\n","from torch.utils.data import DataLoader\n","\n","train_dataset = data_loader('./MELD/data/MELD/train_sent_emo.csv')\n","dev_dataset = data_loader('./MELD/data/MELD/dev_sent_emo.csv')\n","test_dataset = data_loader('./MELD/data/MELD/test_sent_emo.csv')\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4, collate_fn=train_dataset.collate_fn)\n","dev_dataloader = DataLoader(dev_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=test_dataset.collate_fn)"]},{"cell_type":"code","execution_count":null,"id":"ce6d2782-bbf8-4318-a5e6-415175c3a0cd","metadata":{"id":"ce6d2782-bbf8-4318-a5e6-415175c3a0cd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662191402730,"user_tz":-540,"elapsed":5,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"2ed07144-a928-486c-85bb-9a53dd8db4a4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9989, 1109, 2610)"]},"metadata":{},"execution_count":2}],"source":["len(train_dataloader), len(dev_dataloader), len(test_dataloader)"]},{"cell_type":"code","execution_count":null,"id":"f7ebe0f3-ac89-4d24-8dbf-085d72d0e0ea","metadata":{"id":"f7ebe0f3-ac89-4d24-8dbf-085d72d0e0ea"},"outputs":[],"source":["from model import ERC_model\n","clsNum = len(train_dataset.emoList)\n","erc_model = ERC_model(clsNum).cuda()"]},{"cell_type":"code","source":["## GPU 작동 모델 수정\n","from transformers import RobertaModel\n","import torch\n","import torch.nn as nn\n","\n","class ERC_model(nn.Module):\n","    def __init__(self, clsNum):\n","        super(ERC_model, self).__init__()\n","        self.com_model = RobertaModel.from_pretrained('roberta-base')\n","        self.pm_model = RobertaModel.from_pretrained('roberta-base')\n","        \n","        \"\"\" GRU 세팅 \"\"\"\n","        self.hiddenDim = self.com_model.config.hidden_size\n","        zero = torch.empty(2, 1, self.hiddenDim)\n","        self.h0 = torch.zeros_like(zero).cuda() # (num_layers * num_directions, batch, hidden_size)\n","        self.speakerGRU = nn.GRU(self.hiddenDim, self.hiddenDim, 2, dropout=0.3) # (input, hidden, num_layer) (BERT_emb, BERT_emb, num_layer)\n","        \n","        \"\"\" score matrix \"\"\"\n","        self.W = nn.Linear(self.hiddenDim, clsNum)\n","    def forward(self, batch_padding_token, batch_padding_attention_mask, batch_PM_input):\n","        \"\"\" for CoM \"\"\"\n","        batch_com_out = self.com_model(input_ids=batch_padding_token, attention_mask=batch_padding_attention_mask)['last_hidden_state']\n","        batch_com_final = batch_com_out[:,0,:]\n","        \n","        \"\"\" GRU 통과 --> PM 결과 \"\"\"\n","        batch_pm_gru_final = []\n","        for PM_inputs in batch_PM_input:\n","            if PM_inputs:\n","                pm_outs = []\n","                for PM_input in PM_inputs:\n","                    pm_out = self.pm_model(PM_input)['last_hidden_state'][:,0,:]\n","                    pm_outs.append(pm_out)\n","                pm_outs = torch.cat(pm_outs, 0).unsqueeze(1) # (speaker_num, batch=1, hidden_dim)\n","                pm_gru_outs, _ = self.speakerGRU(pm_outs, self.h0) # (speaker_num, batch=1, hidden_dim)\n","                pm_gru_final = pm_gru_outs[-1,:,:] # (1, hidden_dim)\n","                batch_pm_gru_final.append(pm_gru_final)\n","            else:\n","                batch_pm_gru_final.append(torch.zeros(1, self.hiddenDim).cuda())\n","        batch_pm_gru_final = torch.cat(batch_pm_gru_final, 0)        \n","        \n","        \"\"\" score matrix \"\"\"\n","        final_output = self.W(batch_com_final + batch_pm_gru_final) # (B, C)\n","        \n","        return final_output"],"metadata":{"id":"1yJ-E1bRRES_"},"id":"1yJ-E1bRRES_","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"9c8095ce-9cf5-429c-a84c-8ebd75c5f197","metadata":{"id":"9c8095ce-9cf5-429c-a84c-8ebd75c5f197"},"outputs":[],"source":["import torch.nn as nn\n","def CELoss(pred_outs, labels):\n","    \"\"\"\n","        pred_outs: [batch, clsNum]\n","        labels: [batch]\n","    \"\"\"\n","    loss = nn.CrossEntropyLoss()\n","    loss_val = loss(pred_outs, labels)\n","    return loss_val"]},{"cell_type":"code","execution_count":null,"id":"4ebce18f-8b5c-4f96-a2cd-3e8c530c39b2","metadata":{"id":"4ebce18f-8b5c-4f96-a2cd-3e8c530c39b2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662193581420,"user_tz":-540,"elapsed":887,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"41574e39-a3ff-429f-e482-689e587f00a5"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","  0%|          | 0/5 [00:00<?, ?it/s]\n"]}],"source":["import torch\n","from transformers import get_linear_schedule_with_warmup\n","from tqdm import tqdm\n","import pdb\n","\n","training_epochs = 5\n","max_grad_norm = 10\n","lr = 1e-6\n","num_training_steps = len(train_dataset)*training_epochs\n","num_warmup_steps = len(train_dataset)\n","optimizer = torch.optim.AdamW(erc_model.parameters(), lr=lr) # , eps=1e-06, weight_decay=0.01\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n","\n","for epoch in tqdm(range(training_epochs)):\n","    erc_model.train() \n","    for i_batch, data in enumerate(train_dataloader):\n","        batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n","        batch_padding_token = batch_padding_token.cuda()\n","        batch_padding_attention_mask = batch_padding_attention_mask.cuda()\n","        batch_PM_input = [[x2.cuda() for x2 in x1] for x1 in batch_PM_input]\n","        batch_label = batch_label.cuda()        \n","        \n","        \"\"\"Prediction\"\"\"\n","        pred_logits = erc_model(batch_padding_token, batch_padding_attention_mask, batch_PM_input)\n","        \n","        \"\"\"Loss calculation & training\"\"\"\n","        loss_val = CELoss(pred_logits, batch_label)\n","        \n","        loss_val.backward()\n","        torch.nn.utils.clip_grad_norm_(erc_model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()        \n","        break\n","    break"]},{"cell_type":"markdown","id":"7640a37b-f693-44b9-9d14-a3642c1bc232","metadata":{"id":"7640a37b-f693-44b9-9d14-a3642c1bc232"},"source":["## 모델 저장하기"]},{"cell_type":"code","execution_count":null,"id":"39f876a4-ebaa-4a32-9747-bcf10987fce6","metadata":{"id":"39f876a4-ebaa-4a32-9747-bcf10987fce6"},"outputs":[],"source":["import os\n","def SaveModel(model, path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","    torch.save(model.state_dict(), os.path.join(path, 'model.bin'))"]},{"cell_type":"code","source":["import math\n","a = -(0.8*math.log(0.8)+0.2*math.log(0.2))\n","b = -(0.8*math.log(0.5)+0.2*math.log(0.5))\n","a, b"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1EIL_F59C5tN","executionInfo":{"status":"ok","timestamp":1663998848410,"user_tz":-540,"elapsed":499,"user":{"displayName":"이주성","userId":"05491312179909265297"}},"outputId":"d4abe77e-5cb0-4b50-b6e9-ca6b334ea14f"},"id":"1EIL_F59C5tN","execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.5004024235381879, 0.6931471805599453)"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","id":"fe335f83-9080-4120-9046-718044877b57","metadata":{"id":"fe335f83-9080-4120-9046-718044877b57"},"source":["## 최종 학습 코드"]},{"cell_type":"code","execution_count":null,"id":"8d3a195c-4677-486a-98b4-3b0f6dacfed0","metadata":{"id":"8d3a195c-4677-486a-98b4-3b0f6dacfed0"},"outputs":[],"source":["import torch\n","from transformers import get_linear_schedule_with_warmup\n","from tqdm import tqdm\n","\n","training_epochs = 5\n","max_grad_norm = 10\n","lr = 1e-6\n","num_training_steps = len(train_dataset)*training_epochs\n","num_warmup_steps = len(train_dataset)\n","optimizer = torch.optim.AdamW(erc_model.parameters(), lr=lr) # , eps=1e-06, weight_decay=0.01\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n","\n","best_dev_fscore = 0\n","save_path = '.'\n","for epoch in tqdm(range(training_epochs)):\n","    erc_model.train() \n","    for i_batch, data in enumerate(tqdm(train_dataloader)):\n","        batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n","        batch_padding_token = batch_padding_token.cuda()\n","        batch_padding_attention_mask = batch_padding_attention_mask.cuda()\n","        batch_PM_input = [[x2.cuda() for x2 in x1] for x1 in batch_PM_input]\n","        batch_label = batch_label.cuda()        \n","        \n","        \"\"\"Prediction\"\"\"\n","        pred_logits = erc_model(batch_padding_token, batch_padding_attention_mask, batch_PM_input)\n","        \n","        \"\"\"Loss calculation & training\"\"\"\n","        loss_val = CELoss(pred_logits, batch_label)\n","        \n","        loss_val.backward()\n","        torch.nn.utils.clip_grad_norm_(erc_model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","    \n","    \"\"\"Dev & Test evaluation\"\"\"\n","    erc_model.eval()\n","    \n","    dev_acc, dev_pred_list, dev_label_list = CalACC(erc_model, dev_dataloader)\n","    dev_pre, dev_rec, dev_fbeta, _ = precision_recall_fscore_support(dev_label_list, dev_pred_list, average='weighted')\n","    \n","    print(\"Dev W-avg F1: {}\".format(dev_fbeta))\n","\n","    \"\"\"Best Score & Model Save\"\"\"\n","    if dev_fbeta > best_dev_fscore:\n","        best_dev_fscore = dev_fbeta\n","\n","        test_acc, test_pred_list, test_label_list = CalACC(erc_model, test_dataloader)\n","        test_pre, test_rec, test_fbeta, _ = precision_recall_fscore_support(test_label_list, test_pred_list, average='weighted')                \n","\n","        SaveModel(erc_model, save_path)\n","        print(\"Test W-avg F1: {}\".format(test_fbeta))"]},{"cell_type":"markdown","id":"276d9280-588c-40fa-bb11-9cc6a56006ba","metadata":{"id":"276d9280-588c-40fa-bb11-9cc6a56006ba"},"source":["## 파일로 저장하기"]},{"cell_type":"code","source":["import torch\n","from transformers import get_linear_schedule_with_warmup\n","from tqdm import tqdm\n","\n","import os\n","from sklearn.metrics import precision_recall_fscore_support\n","import torch.nn as nn\n","import pdb\n","\n","import logging\n","\n","# 로그 생성\n","logger = logging.getLogger()\n","\n","# 로그의 출력 기준 설정\n","logger.setLevel(logging.INFO)\n","\n","# log 출력\n","stream_handler = logging.StreamHandler()\n","logger.addHandler(stream_handler)\n","\n","# log를 파일에 출력\n","file_handler = logging.FileHandler('erc.log')\n","logger.addHandler(file_handler)\n","\n","def CELoss(pred_outs, labels):\n","    \"\"\"\n","        pred_outs: [batch, clsNum]\n","        labels: [batch]\n","    \"\"\"\n","    loss = nn.CrossEntropyLoss()\n","    loss_val = loss(pred_outs, labels)\n","    return loss_val\n","\n","def SaveModel(model, path):\n","    if not os.path.exists(path):\n","        os.makedirs(path)\n","    torch.save(model.state_dict(), os.path.join(path, 'model.bin'))\n","    \n","def CalACC(model, dataloader):\n","    model.eval()\n","    correct = 0\n","    label_list = []\n","    pred_list = []\n","    \n","    # label arragne\n","    with torch.no_grad():\n","        for i_batch, data in enumerate(tqdm(dataloader)):\n","            \"\"\"Prediction\"\"\"\n","            batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n","            batch_padding_token = batch_padding_token.cuda()\n","            batch_padding_attention_mask = batch_padding_attention_mask.cuda()\n","            batch_PM_input = [[x2.cuda() for x2 in x1] for x1 in batch_PM_input]\n","            batch_label = batch_label.cuda()        \n","\n","            \"\"\"Prediction\"\"\"\n","            pred_logits = erc_model(batch_padding_token, batch_padding_attention_mask, batch_PM_input)\n","            \n","            \"\"\"Calculation\"\"\"    \n","            pred_label = pred_logits.argmax(1).item()\n","            true_label = batch_label.item()\n","            \n","            pred_list.append(pred_label)\n","            label_list.append(true_label)\n","            if pred_label == true_label:\n","                correct += 1\n","        acc = correct/len(dataloader)\n","    return acc, pred_list, label_list\n","\n","from dataset import data_loader\n","from torch.utils.data import DataLoader\n","\n","train_dataset = data_loader('./MELD/data/MELD/train_sent_emo.csv')\n","dev_dataset = data_loader('./MELD/data/MELD/dev_sent_emo.csv')\n","test_dataset = data_loader('./MELD/data/MELD/test_sent_emo.csv')\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4, collate_fn=train_dataset.collate_fn)\n","dev_dataloader = DataLoader(dev_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=dev_dataset.collate_fn)\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=test_dataset.collate_fn)\n","\n","from model import ERC_model\n","clsNum = len(train_dataset.emoList)\n","erc_model = ERC_model(clsNum).cuda()\n","\n","\"\"\" 하이퍼 파라미터들 \"\"\"\n","training_epochs = 10\n","max_grad_norm = 10\n","lr = 1e-6\n","num_training_steps = len(train_dataset)*training_epochs\n","num_warmup_steps = len(train_dataset)\n","optimizer = torch.optim.AdamW(erc_model.parameters(), lr=lr) # , eps=1e-06, weight_decay=0.01\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n","\n","logger.info(\"############학습 시작############\")\n","best_dev_fscore = 0\n","save_path = '.'\n","for epoch in tqdm(range(training_epochs)):\n","    erc_model.train() \n","    for i_batch, data in enumerate(tqdm(train_dataloader)):\n","        batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n","        batch_padding_token = batch_padding_token.cuda()\n","        batch_padding_attention_mask = batch_padding_attention_mask.cuda()\n","        batch_PM_input = [[x2.cuda() for x2 in x1] for x1 in batch_PM_input]\n","        batch_label = batch_label.cuda()        \n","        \n","        \"\"\"Prediction\"\"\"\n","        pred_logits = erc_model(batch_padding_token, batch_padding_attention_mask, batch_PM_input)\n","        \n","        \"\"\"Loss calculation & training\"\"\"\n","        loss_val = CELoss(pred_logits, batch_label)\n","        \n","        loss_val.backward()\n","        torch.nn.utils.clip_grad_norm_(erc_model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()\n","        optimizer.zero_grad()\n","    \n","    \"\"\"Dev & Test evaluation\"\"\"\n","    erc_model.eval()\n","    \n","    dev_acc, dev_pred_list, dev_label_list = CalACC(erc_model, dev_dataloader)\n","    dev_pre, dev_rec, dev_fbeta, _ = precision_recall_fscore_support(dev_label_list, dev_pred_list, average='weighted')\n","    \n","    logger.info(\"Dev W-avg F1: {}\".format(dev_fbeta))\n","    \n","    test_acc, test_pred_list, test_label_list = CalACC(erc_model, test_dataloader)\n","    \"\"\"Best Score & Model Save\"\"\"\n","    if dev_fbeta > best_dev_fscore:\n","        best_dev_fscore = dev_fbeta\n","\n","        test_acc, test_pred_list, test_label_list = CalACC(erc_model, test_dataloader)\n","        test_pre, test_rec, test_fbeta, _ = precision_recall_fscore_support(test_label_list, test_pred_list, average='weighted')                \n","\n","        SaveModel(erc_model, save_path)\n","        logger.info(\"Epoch:{}, Test W-avg F1: {}\".format(epoch, test_fbeta))"],"metadata":{"id":"x-RNq2uYYORU"},"id":"x-RNq2uYYORU","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"7ff2c82a-1ae6-4312-a603-3ab21f245426","metadata":{"id":"7ff2c82a-1ae6-4312-a603-3ab21f245426"},"outputs":[],"source":["!touch train.py\n","# 복사하기"]},{"cell_type":"code","source":["!python3 train.py"],"metadata":{"id":"CYb5Ra1dXyNW"},"id":"CYb5Ra1dXyNW","execution_count":null,"outputs":[]},{"cell_type":"code","source":["screen tmux nohup"],"metadata":{"id":"bMzpumCS4cD_"},"id":"bMzpumCS4cD_","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"9769b7ee-b5bf-4ddc-a6a9-72ed6a723d2c","metadata":{"id":"9769b7ee-b5bf-4ddc-a6a9-72ed6a723d2c"},"source":["# 모델 성능 확인"]},{"cell_type":"code","execution_count":null,"id":"d5269546-f36f-4528-afb9-77f97168dcfc","metadata":{"id":"d5269546-f36f-4528-afb9-77f97168dcfc"},"outputs":[],"source":["!python3 train.py\n","# CoM과 PM 모두 roberta-base\n","# CoMPM 성능: 0.6312649215270238\n","# CoM 성능: 0.6217757422764041 \n","\n","# CoM과 PM 모두 roberta-large\n","# CoMPM 성능: 0.6511452632509548\n","# CoM 성능: 0.6475731666292399"]},{"cell_type":"markdown","id":"da293533-0ca6-4283-96c5-4c917136b5af","metadata":{"id":"da293533-0ca6-4283-96c5-4c917136b5af"},"source":["# 에러 케이스 확인하기"]},{"cell_type":"code","execution_count":null,"id":"b46fbb43-f37b-4c44-b8a3-db7a29852cbd","metadata":{"id":"b46fbb43-f37b-4c44-b8a3-db7a29852cbd"},"outputs":[],"source":["import torch\n","from dataset import data_loader\n","from torch.utils.data import DataLoader\n","\n","test_dataset = data_loader('./MELD/data/MELD/test_sent_emo.csv')\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4, collate_fn=test_dataset.collate_fn)\n","\n","from model import ERC_model\n","clsNum = len(test_dataset.emoList)\n","erc_model = ERC_model(clsNum).cuda()\n","model_path = './model.bin'\n","erc_model.load_state_dict(torch.load(model_path))\n","erc_model.eval()\n","print('')"]},{"cell_type":"code","execution_count":null,"id":"88ee3d8c-c73a-4a80-88b3-e0ad725f96a1","metadata":{"id":"88ee3d8c-c73a-4a80-88b3-e0ad725f96a1"},"outputs":[],"source":["from tqdm import tqdm\n","def ErrorSamples(model, dataloader):\n","    model.eval()\n","    correct = 0\n","    label_list = []\n","    pred_list = []    \n","    \n","    error_samples = []\n","    # label arragne\n","    with torch.no_grad():\n","        for i_batch, data in enumerate(tqdm(dataloader)):\n","            \"\"\"Prediction\"\"\"\n","            batch_padding_token, batch_padding_attention_mask, batch_PM_input, batch_label = data\n","            batch_padding_token = batch_padding_token.cuda()\n","            batch_padding_attention_mask = batch_padding_attention_mask.cuda()\n","            batch_PM_input = [[x2.cuda() for x2 in x1] for x1 in batch_PM_input]\n","            batch_label = batch_label.cuda()        \n","\n","            \"\"\"Prediction\"\"\"\n","            pred_logits = erc_model(batch_padding_token, batch_padding_attention_mask, batch_PM_input)\n","            \n","            \"\"\"Calculation\"\"\"    \n","            pred_label = pred_logits.argmax(1).item()\n","            true_label = batch_label.item()\n","            \n","            pred_list.append(pred_label)\n","            label_list.append(true_label)            \n","            if pred_label != true_label:\n","                error_samples.append([batch_padding_token, true_label, pred_label])\n","            if pred_label == true_label:\n","                correct += 1\n","        acc = correct/len(dataloader)                \n","    return error_samples, acc, pred_list, label_list"]},{"cell_type":"code","execution_count":null,"id":"475a4a73-a2a2-4914-abb2-10013d059178","metadata":{"id":"475a4a73-a2a2-4914-abb2-10013d059178"},"outputs":[],"source":["error_samples, acc, pred_list, label_list = ErrorSamples(erc_model, test_dataloader)"]},{"cell_type":"code","execution_count":null,"id":"f7745de7-1c39-49c3-b326-ad04b70ffb68","metadata":{"id":"f7745de7-1c39-49c3-b326-ad04b70ffb68"},"outputs":[],"source":["import random\n","random_error_samples = random.sample(error_samples, 5)"]},{"cell_type":"code","execution_count":null,"id":"1cd6e448-e3dc-4f6b-b252-427e83d7a040","metadata":{"id":"1cd6e448-e3dc-4f6b-b252-427e83d7a040","outputId":"64589808-4f3f-4032-d86b-86918fb89ba8"},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------------------------------------------------\n","입력 문장들:  <s> Phoebe! Come on! Let’s go!  Come on!  Why aren’t you dressed yet?!</s>\n","정답 감정:  anger\n","예측 감정:  joy\n","--------------------------------------------------------\n","입력 문장들:  <s> Honey, I was wondering....</s> Hmm?</s> Do you still have that, um, Navy uniform?</s> Nooo, I had to return it to the costume place.</s> Hmm.</s> I think I have an old band uniform from high school.</s> You remember not having sex in high school, right?</s>\n","정답 감정:  sadness\n","예측 감정:  neutral\n","--------------------------------------------------------\n","입력 문장들:  <s> Okay, it’s coffee.</s> Ice coffee? Tell me it’s ice coffee!</s> It’s-it’s hot</s> Hot coffee!!!</s> You idiot!!</s> You were gonna spill hot coffee all over me, huh?!!</s> What are you just some big, dumb, stupid, doofy idiot, with a doofy idiot hairdo, huh?!</s> Huh?</s> What’s your favourite thing about summertime?</s> Umm, going to the beach. When it stays light real late.</s> Yeah</s> Hey!</s> Tommyyyy! Say, what’s your favourite thing about summer?</s> Ooh, I don’t know. Probably the smell of freshly cut grass.</s> Ohh, that’s a good one.</s>\n","정답 감정:  joy\n","예측 감정:  neutral\n","--------------------------------------------------------\n","입력 문장들:  <s> I have no idea what you just said.</s>\n","정답 감정:  neutral\n","예측 감정:  surprise\n","--------------------------------------------------------\n","입력 문장들:  <s> Oh.</s> But I don't. Me, Phoebe.</s> Well, I'm not I'm not at all surprised they feel that way.</s> You're not? See, that's why you're so great!</s> Actually it's, it's quite, y'know, typical behaviour when you have this kind of dysfunctional group dynamic.</s> Y'know, this kind of co-dependant, emotionally stunted, sitting in your stupid coffee house with your stupid big cups which, I'm sorry, might as well have nipples on them, and you're like all 'Oh, define me!</s>\n","정답 감정:  anger\n","예측 감정:  disgust\n"]}],"source":["for random_error_sample in random_error_samples:\n","    batch_padding_token, true_label, pred_label = random_error_sample\n","    print('--------------------------------------------------------')\n","    print(\"입력 문장들: \", test_dataset.tokenizer.decode(batch_padding_token.squeeze(0).tolist()))\n","    print(\"정답 감정: \", test_dataset.emoList[true_label])\n","    print(\"예측 감정: \", test_dataset.emoList[pred_label])"]},{"cell_type":"markdown","source":["## 더 나은 모델을 만들기 위한 요소"],"metadata":{"id":"yDTCjIPdrZn0"},"id":"yDTCjIPdrZn0"},{"cell_type":"code","execution_count":null,"id":"633ceee8-ecf0-44c2-83c7-3cfb22333155","metadata":{"id":"633ceee8-ecf0-44c2-83c7-3cfb22333155","outputId":"f84243f8-91bc-4f05-b3b0-1ed2c8b8c208"},"outputs":[{"data":{"text/plain":["0.6312649215270238"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["## speaker 구분 안했음.\n","## CLS 토큰 위치변경 혹은 special token으로 예측할 발화 추가\n","## post-training을 해주면 좋을 듯\n","## 감정간의 상관관계\n","## 모델링적인 개선"]},{"cell_type":"code","execution_count":null,"id":"63c9b367-41b8-4cdc-a688-d0767e51c5cc","metadata":{"id":"63c9b367-41b8-4cdc-a688-d0767e51c5cc"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"provenance":[],"collapsed_sections":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"4a67d2a5a2b8497e978941315e73ee57":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9bdd70ccdd3e4e2e908ea7934350c30d","IPY_MODEL_a6ce41255b454c08b96dd7eb05a44641","IPY_MODEL_fc8dd8e8e38842678b009fbf2af1ca86"],"layout":"IPY_MODEL_3bbf238354dc4aa88fdb7fae8da2c473"}},"9bdd70ccdd3e4e2e908ea7934350c30d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3dd949c5b75c4d108b7bbe44460c56cf","placeholder":"​","style":"IPY_MODEL_e8be32bd5baf43ae93eef123dd5a042f","value":"Downloading: 100%"}},"a6ce41255b454c08b96dd7eb05a44641":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_982341076c7e462c8d88752531e3d7fd","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_63c1a6ff1488408489875f83c88bf540","value":898823}},"fc8dd8e8e38842678b009fbf2af1ca86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6000a3950b9f47de95046e894255c27d","placeholder":"​","style":"IPY_MODEL_d844a2b9c9334c11bb909b2be9682d55","value":" 899k/899k [00:01&lt;00:00, 943kB/s]"}},"3bbf238354dc4aa88fdb7fae8da2c473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3dd949c5b75c4d108b7bbe44460c56cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8be32bd5baf43ae93eef123dd5a042f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"982341076c7e462c8d88752531e3d7fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63c1a6ff1488408489875f83c88bf540":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6000a3950b9f47de95046e894255c27d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d844a2b9c9334c11bb909b2be9682d55":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a54b8f39ad84433f8cf5f70456b86fc1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afd9c10670434e9999dbd495ed53fab9","IPY_MODEL_ebbc39fe81324996a42cb3819ad582c0","IPY_MODEL_372da0def3e64334adb67e9582802ff9"],"layout":"IPY_MODEL_d9547e48fc6b4d5db9a27f112241be90"}},"afd9c10670434e9999dbd495ed53fab9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a703cb42a6c9406599aeb9d59e84bead","placeholder":"​","style":"IPY_MODEL_2a77f20be08f485f835a36344d2f14af","value":"Downloading: 100%"}},"ebbc39fe81324996a42cb3819ad582c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a345546660af4090aadda2ab60079584","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_da5c999b5e6d4898930b22a37cd56ea0","value":456318}},"372da0def3e64334adb67e9582802ff9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa8ea8931b2144748e5eb8615bb1134c","placeholder":"​","style":"IPY_MODEL_6675f8e717554f3abdb0b8b132798165","value":" 456k/456k [00:01&lt;00:00, 440kB/s]"}},"d9547e48fc6b4d5db9a27f112241be90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a703cb42a6c9406599aeb9d59e84bead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a77f20be08f485f835a36344d2f14af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a345546660af4090aadda2ab60079584":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da5c999b5e6d4898930b22a37cd56ea0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa8ea8931b2144748e5eb8615bb1134c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6675f8e717554f3abdb0b8b132798165":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"181b177cb9c24073a23f66c1633d54fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c469069e97014e38b08c19e407b62c3b","IPY_MODEL_87c6ba6b21da4920b9c11e96bca61d9c","IPY_MODEL_0ca6cbdc7ecd45fb965a06b503e6431b"],"layout":"IPY_MODEL_a24f3b696817480d86aa63a36130f516"}},"c469069e97014e38b08c19e407b62c3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_76a84ecdf66b48ceaf4a39b9d7c635c0","placeholder":"​","style":"IPY_MODEL_b8eb05407a684b9299a688bf0d9115dd","value":"Downloading: 100%"}},"87c6ba6b21da4920b9c11e96bca61d9c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4f3416d7b30467db737c2b861499504","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cbebf21792724ee9bc2753c2dade04c6","value":1355863}},"0ca6cbdc7ecd45fb965a06b503e6431b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9226cb4723eb456292570d29c5b85b66","placeholder":"​","style":"IPY_MODEL_0ed7c78cb6cf41ffb3c05fe313fdfea3","value":" 1.36M/1.36M [00:01&lt;00:00, 1.06MB/s]"}},"a24f3b696817480d86aa63a36130f516":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76a84ecdf66b48ceaf4a39b9d7c635c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8eb05407a684b9299a688bf0d9115dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4f3416d7b30467db737c2b861499504":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbebf21792724ee9bc2753c2dade04c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9226cb4723eb456292570d29c5b85b66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ed7c78cb6cf41ffb3c05fe313fdfea3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}